import edu.stanford.nlp.util.logging.Redwood;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.util.List;

import edu.stanford.nlp.ling.SentenceUtils;
import edu.stanford.nlp.ling.TaggedWord;
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.tagger.maxent.MaxentTagger;

public class POSWrapper {
	
	/** A logger for this class */
	  private static Redwood.RedwoodChannels log = Redwood.channels(POSWrapper.class);
  
	public static void main(String[] args) throws Exception {
		if (args.length != 2) {
	      log.info("usage: java TaggerDemo modelFile fileToTag");
	      //return;
	    }
	    MaxentTagger tagger = new MaxentTagger("/models/english-left3words-distsim.tagger");
	    System.out.println(System.getProperty("user.dir"));
	    List<List<HasWord>> sentences = MaxentTagger.tokenizeText(new BufferedReader(new FileReader("sample-input.txt")));
	    for (List<HasWord> sentence : sentences) {
	      List<TaggedWord> tSentence = tagger.tagSentence(sentence);
	      System.out.println("Starting new line");
	      for (TaggedWord taggedWord: tSentence) {
	    	  System.out.println(taggedWord.tag()+" " + taggedWord.word());
	      }
	      //System.out.println(SentenceUtils.listToString(tSentence, false)+ "\n");
	    }	
	}
}
